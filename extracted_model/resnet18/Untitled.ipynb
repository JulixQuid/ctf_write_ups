{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4da0c43a-dce9-47ad-9571-e3049c7ba562",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "952347f1-5a0e-4bb0-aa9a-63ab3028d995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_min_max(arr):\n",
    "    min_val = np.min(arr)\n",
    "    max_val = np.max(arr)\n",
    "    return (arr - min_val) / (max_val - min_val)\n",
    "\n",
    "def load_original():\n",
    "    a = AudioSegment.from_mp3(\"/home/julixquid/Downloads/ml (2)/ml/original.mp3\")\n",
    "    b = a.set_frame_rate(44100).set_channels(1)\n",
    "    y = np.array(b.get_array_of_samples())\n",
    "    y = normalize_min_max(y)\n",
    "    y = np.pad(y, (0, 80000 - len(y)), mode='constant', constant_values=0)\n",
    "    return y[:-1].astype(np.float32).reshape(1, 1, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c6d24d0-76a7-465f-afab-4dfa5d5ce4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = AudioSegment.from_mp3(\"/home/julixquid/Downloads/ml (2)/ml/original.mp3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "008c2586-0299-43d5-97d9-026df3bde5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.set_frame_rate(44100).set_channels(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8bd24c73-0bd5-4ad5-94b6-2ea1159c4f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(b.get_array_of_samples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8db1ee8-185c-4672-9653-b70b058c8e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33171/2004056986.py:4: RuntimeWarning: overflow encountered in scalar subtract\n",
      "  return (arr - min_val) / (max_val - min_val)\n"
     ]
    }
   ],
   "source": [
    "y = normalize_min_max(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7359b255-bff2-4e39-af7f-51e77e79bce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.pad(y, (0, 80000 - len(y)), mode='constant', constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "26a10ac3-0879-45a7-b62a-fa5248dd66e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33171/3974179784.py:4: RuntimeWarning: overflow encountered in scalar subtract\n",
      "  return (arr - min_val) / (max_val - min_val)\n"
     ]
    }
   ],
   "source": [
    "arr = load_original()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "07391d45-656c-4439-b4d0-ba4833b018e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array saved to array_data.txt\n"
     ]
    }
   ],
   "source": [
    "flattened_arr = best_input.flatten()\n",
    "\n",
    "# Step 2: Convert to Python list and format as string\n",
    "array_str = \"[\" + \", \".join(map(str, flattened_arr.tolist())) + \"]\"\n",
    "\n",
    "# Step 3: Save to text file\n",
    "with open(\"array_data.txt\", \"w\") as f:\n",
    "    f.write(array_str)\n",
    "\n",
    "print(\"Array saved to array_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b81d8f5c-d392-4e93-a3e1-067d0432c531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv1DNet(\n",
       "  (conv1): Conv1d(1, 16, kernel_size=(3,), stride=(1,))\n",
       "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv1d(16, 32, kernel_size=(3,), stride=(1,))\n",
       "  (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv1d(32, 64, kernel_size=(3,), stride=(1,))\n",
       "  (global_pool): AdaptiveMaxPool1d(output_size=1)\n",
       "  (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=2, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# --- Define the neural network (same as in Flask app) ---\n",
    "class Conv1DNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Conv1DNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 16, kernel_size=3)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(16, 32, kernel_size=3)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "        self.conv3 = nn.Conv1d(32, 64, kernel_size=3)\n",
    "        self.global_pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.fc1 = nn.Linear(64, 64)\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# --- Load the pretrained model ---\n",
    "model = Conv1DNet(num_classes=2)\n",
    "model.load_state_dict(tor\tKalmarCTF 2025\t209.0000\t0.983ch.load('/home/julixquid/Downloads/ml (2)/ml/model_weights.pth'))#, map_location='cpu'))\n",
    "model.eval()  # Disable dropout/batchnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8ec7b99f-4f6d-4989-a18a-bae4f0784be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0: Best P(class=1) = 0.98325127363204956\n",
      "Generation 50: Best P(class=1) = 0.98377984762191772\n",
      "Generation 100: Best P(class=1) = 0.98412895202636719\n",
      "Generation 150: Best P(class=1) = 0.98425227403640747\n",
      "Generation 200: Best P(class=1) = 0.98431360721588135\n",
      "Generation 250: Best P(class=1) = 0.98435312509536743\n",
      "Generation 300: Best P(class=1) = 0.98438489437103271\n",
      "Generation 350: Best P(class=1) = 0.98441547155380249\n",
      "Generation 400: Best P(class=1) = 0.98444181680679321\n",
      "Generation 450: Best P(class=1) = 0.98446214199066162\n",
      "Generation 500: Best P(class=1) = 0.98447477817535400\n",
      "Generation 550: Best P(class=1) = 0.98450583219528198\n",
      "Generation 600: Best P(class=1) = 0.98451578617095947\n",
      "Generation 650: Best P(class=1) = 0.98452579975128174\n",
      "Generation 700: Best P(class=1) = 0.98454165458679199\n",
      "Generation 750: Best P(class=1) = 0.98454916477203369\n",
      "Generation 800: Best P(class=1) = 0.98456788063049316\n",
      "Generation 850: Best P(class=1) = 0.98457700014114380\n",
      "Generation 900: Best P(class=1) = 0.98458647727966309\n",
      "Generation 950: Best P(class=1) = 0.98459398746490479\n",
      "Generation 1000: Best P(class=1) = 0.98460417985916138\n",
      "Generation 1050: Best P(class=1) = 0.98461341857910156\n",
      "Generation 1100: Best P(class=1) = 0.98462349176406860\n",
      "Generation 1150: Best P(class=1) = 0.98463535308837891\n",
      "Generation 1200: Best P(class=1) = 0.98464345932006836\n",
      "Generation 1250: Best P(class=1) = 0.98465269804000854\n",
      "Generation 1300: Best P(class=1) = 0.98466378450393677\n",
      "Generation 1350: Best P(class=1) = 0.98467653989791870\n",
      "Generation 1400: Best P(class=1) = 0.98468667268753052\n",
      "Generation 1450: Best P(class=1) = 0.98469650745391846\n",
      "Generation 1500: Best P(class=1) = 0.98470520973205566\n",
      "Generation 1550: Best P(class=1) = 0.98471421003341675\n",
      "Generation 1600: Best P(class=1) = 0.98473441600799561\n",
      "Generation 1650: Best P(class=1) = 0.98474496603012085\n",
      "Generation 1700: Best P(class=1) = 0.98475664854049683\n",
      "Generation 1750: Best P(class=1) = 0.98476451635360718\n",
      "Generation 1800: Best P(class=1) = 0.98477745056152344\n",
      "Generation 1850: Best P(class=1) = 0.98478668928146362\n",
      "Generation 1900: Best P(class=1) = 0.98480474948883057\n",
      "Generation 1950: Best P(class=1) = 0.98482239246368408\n",
      "Generation 2000: Best P(class=1) = 0.98482972383499146\n",
      "Generation 2050: Best P(class=1) = 0.98484253883361816\n",
      "Generation 2100: Best P(class=1) = 0.98485523462295532\n",
      "Generation 2150: Best P(class=1) = 0.98486417531967163\n",
      "Generation 2200: Best P(class=1) = 0.98487710952758789\n",
      "Generation 2250: Best P(class=1) = 0.98489272594451904\n",
      "Generation 2300: Best P(class=1) = 0.98490071296691895\n",
      "Generation 2350: Best P(class=1) = 0.98490935564041138\n",
      "Generation 2400: Best P(class=1) = 0.98492026329040527\n",
      "Generation 2450: Best P(class=1) = 0.98492681980133057\n",
      "Generation 2500: Best P(class=1) = 0.98494523763656616\n",
      "Generation 2550: Best P(class=1) = 0.98495399951934814\n",
      "Generation 2600: Best P(class=1) = 0.98496013879776001\n",
      "Generation 2650: Best P(class=1) = 0.98496556282043457\n",
      "Generation 2700: Best P(class=1) = 0.98497933149337769\n",
      "Generation 2750: Best P(class=1) = 0.98498809337615967\n",
      "Generation 2800: Best P(class=1) = 0.98500156402587891\n",
      "Generation 2850: Best P(class=1) = 0.98500823974609375\n",
      "Generation 2900: Best P(class=1) = 0.98501646518707275\n",
      "Generation 2950: Best P(class=1) = 0.98502838611602783\n",
      "Generation 3000: Best P(class=1) = 0.98503267765045166\n",
      "Generation 3050: Best P(class=1) = 0.98503983020782471\n",
      "Generation 3100: Best P(class=1) = 0.98504501581192017\n",
      "Generation 3150: Best P(class=1) = 0.98505449295043945\n",
      "Generation 3200: Best P(class=1) = 0.98506444692611694\n",
      "Generation 3250: Best P(class=1) = 0.98507153987884521\n",
      "Generation 3300: Best P(class=1) = 0.98508310317993164\n",
      "Generation 3350: Best P(class=1) = 0.98509454727172852\n",
      "Generation 3400: Best P(class=1) = 0.98509937524795532\n",
      "Generation 3450: Best P(class=1) = 0.98510897159576416\n",
      "Generation 3500: Best P(class=1) = 0.98511558771133423\n",
      "Generation 3550: Best P(class=1) = 0.98512822389602661\n",
      "Generation 3600: Best P(class=1) = 0.98513317108154297\n",
      "Generation 3650: Best P(class=1) = 0.98514014482498169\n",
      "Generation 3700: Best P(class=1) = 0.98514556884765625\n",
      "Generation 3750: Best P(class=1) = 0.98514938354492188\n",
      "Generation 3800: Best P(class=1) = 0.98515689373016357\n",
      "Generation 3850: Best P(class=1) = 0.98516142368316650\n",
      "Generation 3900: Best P(class=1) = 0.98516964912414551\n",
      "Generation 3950: Best P(class=1) = 0.98518049716949463\n",
      "Generation 4000: Best P(class=1) = 0.98518723249435425\n",
      "Generation 4050: Best P(class=1) = 0.98519575595855713\n",
      "Generation 4100: Best P(class=1) = 0.98520165681838989\n",
      "Generation 4150: Best P(class=1) = 0.98521208763122559\n",
      "Generation 4200: Best P(class=1) = 0.98521715402603149\n",
      "Generation 4250: Best P(class=1) = 0.98522031307220459\n",
      "Generation 4300: Best P(class=1) = 0.98522317409515381\n",
      "Generation 4350: Best P(class=1) = 0.98522877693176270\n",
      "Generation 4400: Best P(class=1) = 0.98523670434951782\n",
      "Generation 4450: Best P(class=1) = 0.98524492979049683\n",
      "Generation 4500: Best P(class=1) = 0.98525720834732056\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[78]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# --- Evolution Loop ---\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m generation \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_GENERATIONS):\n\u001b[32m     19\u001b[39m     \u001b[38;5;66;03m# 1. Evaluate fitness\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     fitness = [\u001b[43mevaluate_fitness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m population]\n\u001b[32m     21\u001b[39m     best_idx = np.argmax(fitness)\n\u001b[32m     22\u001b[39m     best_fitness = fitness[best_idx]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[78]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mevaluate_fitness\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m      8\u001b[39m x_tensor = torch.tensor(x, dtype=torch.float32).view(\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     output = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     prob_class_1 = torch.softmax(output, dim=\u001b[32m1\u001b[39m)[\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m].item()\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m prob_class_1\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workshop/ctf/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workshop/ctf/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mConv1DNet.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     22\u001b[39m x = \u001b[38;5;28mself\u001b[39m.relu(\u001b[38;5;28mself\u001b[39m.conv2(x))\n\u001b[32m     23\u001b[39m x = \u001b[38;5;28mself\u001b[39m.pool2(x)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m x = \u001b[38;5;28mself\u001b[39m.relu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     25\u001b[39m x = \u001b[38;5;28mself\u001b[39m.global_pool(x)\n\u001b[32m     26\u001b[39m x = x.view(x.size(\u001b[32m0\u001b[39m), -\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workshop/ctf/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workshop/ctf/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workshop/ctf/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:375\u001b[39m, in \u001b[36mConv1d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    374\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workshop/ctf/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:370\u001b[39m, in \u001b[36mConv1d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    359\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv1d(\n\u001b[32m    360\u001b[39m         F.pad(\n\u001b[32m    361\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    368\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    369\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# --- Genetic Algorithm Parameters ---\n",
    "POPULATION_SIZE = 25  # Number of candidates\n",
    "MUTATION_RATE = 0.0007 # Probability of mutation per element\n",
    "NUM_GENERATIONS = 50000  # Max iterations\n",
    "\n",
    "# --- Fitness Function ---\n",
    "def evaluate_fitness(x):\n",
    "    x_tensor = torch.tensor(x, dtype=torch.float32).view(1, 1, -1)\n",
    "    with torch.no_grad():\n",
    "        output = model(x_tensor)\n",
    "        prob_class_1 = torch.softmax(output, dim=1)[0, 1].item()\n",
    "    return prob_class_1  # Higher = better\n",
    "\n",
    "# --- Initialize Population ---\n",
    "population = [best_input]\n",
    "\n",
    "# --- Evolution Loop ---\n",
    "for generation in range(NUM_GENERATIONS):\n",
    "    # 1. Evaluate fitness\n",
    "    fitness = [evaluate_fitness(x) for x in population]\n",
    "    best_idx = np.argmax(fitness)\n",
    "    best_fitness = fitness[best_idx]\n",
    "    \n",
    "    #print(f\"Generation {generation}: Best P(class=1) = {best_fitness:.17f}\")\n",
    "    \n",
    "    # Exit if we fool the network\n",
    "    if best_fitness > 0.99:\n",
    "        print(\"Success! Found adversarial input.\")\n",
    "        break\n",
    "    \n",
    "    # 2. Select top candidates (elite selection)\n",
    "    elite_indices = np.argsort(fitness)[-2:]  # Top 10\n",
    "    elites = [population[i] for i in elite_indices]\n",
    "    \n",
    "    # 3. Breed new population\n",
    "    new_population = elites.copy()  # Keep elites\n",
    "    \n",
    "    while len(new_population) < POPULATION_SIZE:\n",
    "        # Pick a random elite parent\n",
    "        parent = elites[np.random.randint(len(elites))]\n",
    "        \n",
    "        # Create a child with mutation\n",
    "        child = parent.copy()\n",
    "        mask = np.random.rand(79999) < MUTATION_RATE\n",
    "        child[mask] = np.clip(child[mask] + np.random.normal(0, 0.07, size=np.sum(mask)), 0, 1)\n",
    "        \n",
    "        new_population.append(child)\n",
    "    \n",
    "    population = new_population\n",
    "\n",
    "# --- Save the Best Input ---\n",
    "    best_input = population[best_idx]\n",
    "    if (generation % 50)==0:\n",
    "        np.savetxt('adversarial_input.txt', best_input, fmt='%.17f', delimiter=',')\n",
    "        print(f\"Generation {generation}: Best P(class=1) = {best_fitness:.17f}\")\n",
    "print(\"Saved adversarial input to 'adversarial_input.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "74ff82e3-a5f7-4929-b587-f32397316b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34411166, 0.12414883, 0.53693168, ..., 0.20192388, 0.58226629,\n",
       "       0.7813683 ], shape=(79999,))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_input"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
